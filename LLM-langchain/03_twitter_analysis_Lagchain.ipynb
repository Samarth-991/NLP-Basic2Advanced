{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import requests\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import json \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\" \n",
    "os.environ['SERPAPI_API_KEY'] = '836b6623bddd5b44cf8d3e01bd80f262ec123f364591b1e4a35d736b9d7237d0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent , Tool\n",
    "from langchain.agents import AgentType # tells Agent how to calculate the sub task we need to complete \n",
    "from langchain.serpapi import SerpAPIWrapper\n",
    "\n",
    "from tenacity import retry ,wait_random\n",
    "#since the SERP API is not looking where it should be looking at we need to write a custom wrapper\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "class Custom_SerpAPIWrapper(SerpAPIWrapper):\n",
    "    def __init__(self):\n",
    "        super(Custom_SerpAPIWrapper,self).__init__()\n",
    "    @staticmethod\n",
    "    def _process_response(res: dict) -> str:\n",
    "        \n",
    "        # process response from SerpAPI \n",
    "        if 'error' in res.keys():\n",
    "            raise ValueError('got error from SerpAPI')\n",
    "        \n",
    "        if \"answer_box\" in res.keys() and \"answer\" in res[\"answer_box\"].keys():\n",
    "            toret = res[\"answer_box\"][\"answer\"]\n",
    "        \n",
    "        elif \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\n",
    "            toret = res[\"answer_box\"][\"snippet\"]\n",
    "        \n",
    "        elif (\n",
    "            \"answer_box\" in res.keys()\n",
    "            and \"snippet_highlighted_words\" in res[\"answer_box\"].keys()\n",
    "        ):\n",
    "            toret = res[\"answer_box\"][\"snippet_highlighted_words\"][0]\n",
    "        \n",
    "        elif (\n",
    "            \"sports_results\" in res.keys()\n",
    "            and \"game_spotlight\" in res[\"sports_results\"].keys()\n",
    "        ):\n",
    "            toret = res[\"sports_results\"][\"game_spotlight\"]\n",
    "        \n",
    "        elif (\n",
    "            \"knowledge_graph\" in res.keys()\n",
    "            and \"description\" in res[\"knowledge_graph\"].keys()\n",
    "        ):\n",
    "            toret = res[\"knowledge_graph\"][\"description\"]\n",
    "        \n",
    "        # elif \"title\" in res[\"organic_results\"][0].keys():\n",
    "        #     toret = res[\"organic_results\"][0][\"title\"]\n",
    "\n",
    "        elif \"snippet\" in res[\"organic_results\"][0].keys():\n",
    "            toret = res[\"organic_results\"][0][\"link\"]\n",
    "        else:\n",
    "            toret = \"No good search result found\"\n",
    "        return toret\n",
    "\n",
    "\n",
    "def get_profile_url(text:str):\n",
    "    \"\"\" searches for linkdin page\"\"\"\n",
    "    search = Custom_SerpAPIWrapper()\n",
    "    result = search.run(f\"{text}\")\n",
    "    return result \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import logging\n",
    "from datetime import datetime , timezone\n",
    "\n",
    "logger = logging.getLogger(\"twitter\")\n",
    "\n",
    "os.environ['TWITTER_API_KEY']= \"guFGnxTk0ImcIvJiOCHP1oaym\"\n",
    "os.environ['TWITTER_API_SECRET'] = 'bc4B11gSefHJwdCcSeOH15dUPNq9E3LA6v7K0GshlZqNwyJzdz'\n",
    "\n",
    "os.environ['TWITTER_ACCESS_TOKEN'] = '400487742-IGBCpQ9p17Sl5TGrupNR5mL4xs2TuPpI6mHK0fDP'\n",
    "os.environ['TWITTER_ACCESS_SECRET'] = '6aAuGhMeaRM20loi0QYDdkaIbliJxkr4eXDCAdGWtMqyO'\n",
    "\n",
    "os.environ['TWITTER_BEARER_TOKEN'] = \"AAAAAAAAAAAAAAAAAAAAAFShngEAAAAAkTIczGAia9eDtVttGZfPFfnVayY%3DnWlWWfYTD5AzAOG8oXWKpKC9Va0J1pyb7kOTXFimb81RtCOkKl\"\n",
    "\n",
    "twitter_client = tweepy.Client(\n",
    "    bearer_token=os.environ.get('TWITTER_BEARER_TOKEN'),\n",
    "    consumer_key=os.environ.get('TWITTER_API_KEY'),\n",
    "    consumer_secret=os.environ.get('TWITTER_API_SECRET'),\n",
    "    access_token=os.environ.get('TWITTER_ACCESS_TOKEN'),\n",
    "    access_token_secret=os.environ.get('TWITTER_ACCESS_SECRET')\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_user_tweets(username,num_tweets):\n",
    "    \"\"\"\n",
    "    Scrapes a Twitter user's original tweets (i.e., not retweets or replies) and returns them as a list of dictionaries.\n",
    "    Each dictionary has three fields: \"time_posted\" (relative to now), \"text\", and \"url\".\n",
    "    \"\"\"\n",
    "    \n",
    "    user_id = twitter_client.get_user(username=username).data.id\n",
    "    tweets = twitter_client.get_users_tweets(id=user_id,max_results=num_tweets,exclude=['retweets','replies'])\n",
    "\n",
    "    tweet_list = []\n",
    "\n",
    "    for tweet in tweets.data:\n",
    "            tweet_dict = {}\n",
    "            tweet_dict[\"text\"] = tweet['text']\n",
    "            tweet_dict[\n",
    "                \"url\"\n",
    "            ] = f\"https://twitter.com/{username}/status/{tweet.id}\"\n",
    "            tweet_list.append(tweet_dict)\n",
    "\n",
    "    return tweet_list\n",
    "\n",
    "\n",
    "def twitter_lookup_agent(name: str) -> str:\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "    template = \"\"\"given the name {name_of_person} I want you to find a link to their Twitter profile page, and extract from it their username.\n",
    "       In Your Final answer only the person's username\"\"\"\n",
    "\n",
    "    tools_for_agent = [\n",
    "        Tool(\n",
    "            name=\"Crawl Google 4 Twitter profile page\",\n",
    "            func=get_profile_url,\n",
    "            description=\"useful for when you need get the Twitter Page URL\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=tools_for_agent,\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=template, input_variables=[\"name_of_person\"]\n",
    "    )\n",
    "\n",
    "    twitter_username = agent.run(prompt_template.format_prompt(name_of_person=name))\n",
    "\n",
    "    return twitter_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_user_tweets(\"hwchase17\",num_tweets=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkedin_profile_url = linkedin_lookup_agent(name=name)\n",
    "# linkedin_data = scrape_linkedin_profile(linkedin_profile_url=linkedin_profile_url)\n",
    "\n",
    "twitter_username = twitter_lookup_agent(name='Elon Musk')\n",
    "tweets = scrape_user_tweets(username=twitter_username, num_tweets=5)\n",
    "\n",
    "summary_template = \"\"\"\n",
    "        given the Linkedin information {linkedin_information} and twitter {twitter_information} about a person from I want you to create:\n",
    "        1. a short summary\n",
    "        2. two interesting facts about them\n",
    "        3. A topic that may interest them\n",
    "        4. 2 creative Ice breakers to open a conversation with them \n",
    "    \"\"\"\n",
    "\n",
    "summary_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"linkedin_information\", \"twitter_information\"],\n",
    "    template=summary_template,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=1, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=summary_prompt_template)\n",
    "\n",
    "print(chain.run(linkedin_information=linkedin_data, twitter_information=tweets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
