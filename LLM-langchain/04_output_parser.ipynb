{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent , Tool\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = '836b6623bddd5b44cf8d3e01bd80f262ec123f364591b1e4a35d736b9d7237d0'\n",
    "os.environ['OPENAI_API_KEY'] = \"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\" \n",
    "os.environ['PROXYCURL_API_KEY'] = 'oIZkc9gjRGm43huug6xeQg'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Linkdln Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_profile(linkedin_profile_url: str):\n",
    "    \"\"\"scrape information from LinkedIn profiles,\n",
    "    Manually scrape the information from the LinkedIn profile\"\"\"\n",
    "    api_endpoint = \"https://nubela.co/proxycurl/api/v2/linkedin\"\n",
    "    header_dic = {\"Authorization\": f'Bearer {os.environ.get(\"PROXYCURL_API_KEY\")}'}\n",
    "\n",
    "    response = requests.get(\n",
    "        api_endpoint, params={\"url\": linkedin_profile_url}, headers=header_dic\n",
    "    )\n",
    "\n",
    "    data = response.json()\n",
    "    data = {\n",
    "        k: v\n",
    "        for k, v in data.items()\n",
    "        if v not in ([], \"\", \"\", None)\n",
    "        and k not in [\"people_also_viewed\", \"certifications\"]\n",
    "    }\n",
    "    if data.get(\"groups\"):\n",
    "        for group_dict in data.get(\"groups\"):\n",
    "            group_dict.pop(\"profile_pic_url\")\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent for Linkdln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType # tells Agent how to calculate the sub task we need to complete \n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.serpapi import SerpAPIWrapper\n",
    "from tenacity import retry ,wait_random\n",
    "\n",
    "class CustomSerpAPIWrapper(SerpAPIWrapper):\n",
    "    def __init__(self):\n",
    "        super(CustomSerpAPIWrapper, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_response(res: dict) -> str:\n",
    "        \"\"\"Process response from SerpAPI.\"\"\"\n",
    "        if \"error\" in res.keys():\n",
    "            raise ValueError(f\"Got error from SerpAPI: {res['error']}\")\n",
    "        if \"answer_box\" in res.keys() and \"answer\" in res[\"answer_box\"].keys():\n",
    "            toret = res[\"answer_box\"][\"answer\"]\n",
    "        elif \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\n",
    "            toret = res[\"answer_box\"][\"snippet\"]\n",
    "        elif (\n",
    "            \"answer_box\" in res.keys()\n",
    "            and \"snippet_highlighted_words\" in res[\"answer_box\"].keys()\n",
    "        ):\n",
    "            toret = res[\"answer_box\"][\"snippet_highlighted_words\"][0]\n",
    "        elif (\n",
    "            \"sports_results\" in res.keys()\n",
    "            and \"game_spotlight\" in res[\"sports_results\"].keys()\n",
    "        ):\n",
    "            toret = res[\"sports_results\"][\"game_spotlight\"]\n",
    "        elif (\n",
    "            \"knowledge_graph\" in res.keys()\n",
    "            and \"description\" in res[\"knowledge_graph\"].keys()\n",
    "        ):\n",
    "            toret = res[\"knowledge_graph\"][\"description\"]\n",
    "        \n",
    "        elif \"snippet\" in res[\"organic_results\"][0].keys():\n",
    "            toret = res[\"organic_results\"][0][\"link\"]\n",
    "\n",
    "        else:\n",
    "            toret = \"No good search result found\"\n",
    "        return toret\n",
    "\n",
    "\n",
    "def get_profile_url(name: str):\n",
    "    \"\"\"Searches for Linkedin or twitter Profile Page.\"\"\"\n",
    "    search = CustomSerpAPIWrapper()\n",
    "    res = search.run(f\"{name}\")\n",
    "    return res\n",
    "\n",
    "def lookup(name: str) -> str:\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "    template = \"\"\"given the full name {name_of_person} I want you to get it me a link to their Linkedin profile page.\n",
    "                          Your answer should contain only a URL\"\"\"\n",
    "\n",
    "    tools_for_agent = [\n",
    "        Tool(\n",
    "            name=\"Crawl Google 4 linkedin profile page\",\n",
    "            func=get_profile_url,\n",
    "            description=\"useful for when you need get the Linkedin Page URL\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=tools_for_agent,\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "    )\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=template, input_variables=[\"name_of_person\"]\n",
    "    )\n",
    "\n",
    "    linked_profile_url = agent.run(prompt_template.format_prompt(name_of_person=name))\n",
    "    return linked_profile_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = lookup('Eden Marco Udemy')\n",
    "\n",
    "profile = \"https://il.linkedin.com/in/eden-marco\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape LinkdIn Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_profile(linkedin_profile_url: str):\n",
    "    \"\"\"scrape information from LinkedIn profiles,\n",
    "    Manually scrape the information from the LinkedIn profile\"\"\"\n",
    "    api_endpoint = \"https://nubela.co/proxycurl/api/v2/linkedin\"\n",
    "    header_dic = {\"Authorization\": f'Bearer {os.environ.get(\"PROXYCURL_API_KEY\")}'}\n",
    "\n",
    "    response = requests.get(\n",
    "        api_endpoint, params={\"url\": linkedin_profile_url}, headers=header_dic\n",
    "    )\n",
    "\n",
    "    data = response.json()\n",
    "    data = {\n",
    "        k: v\n",
    "        for k, v in data.items()\n",
    "        if v not in ([], \"\", \"\", None)\n",
    "        and k not in [\"people_also_viewed\", \"certifications\"]\n",
    "    }\n",
    "    if data.get(\"groups\"):\n",
    "        for group_dict in data.get(\"groups\"):\n",
    "            group_dict.pop(\"profile_pic_url\")\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    data = {\n",
    "        k:v for k ,v in data.items() \n",
    "        if v not in ([],\"\",\"\",None) and k not in ['people_also_viewed',\"certifications\"]\n",
    "    }\n",
    "    if data.get(\"groups\"):\n",
    "        for group_dict in data.get(\"groups\"):\n",
    "            group_dict.pop('profile_pic_url')\n",
    "    return data\n",
    "\n",
    "data = scrape_linkedin_profile(linkedin_profile_url = profile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask LLM to create a summary for this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prime = clean_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model : gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt \n",
    "summary_template = \"\"\" given the information {information} about  a person from I want you to create:\n",
    "                        1. A short summary as summary:\n",
    "                        2. Two interesting facts about the person as Interesting Facts: \n",
    "                        3. company He is currently working as Company Name and Occupation : \n",
    "                        4. Highlight the key skills of person in bullet points as Key skills : \n",
    "                    \"\"\"\n",
    "summary_prompt_template = PromptTemplate(template=summary_template,input_variables=[\"information\"])\n",
    "# input var is information we run the cahin keyword is information is valid.\n",
    "llm = ChatOpenAI(temperature=1,model_name=\"gpt-3.5-turbo\")\n",
    "print(\"LLM model :\",llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Eden Marco is a Customer Engineer at Google with a background in backend development and education in computer science from Technion.\n",
      "\n",
      "Interesting Facts:\n",
      "1. Eden Marco is a bestselling Udemy instructor with two courses that have over 9k enrolled students and 800+ ratings.\n",
      "2. Before starting his career in tech, Eden Marco served as a captain in the Israel Defense Forces.\n",
      "\n",
      "Company Name and Occupation: Eden Marco is currently working as a Customer Engineer at Google.\n",
      "\n",
      "Key Skills:\n",
      "- Backend Development\n",
      "- Teaching and Education\n",
      "- Cloud Computing\n",
      "- Software Engineering\n",
      "- Computer Science\n",
      "- Functional Programming\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=summary_prompt_template)\n",
    "print(chain.run(information=data_prime))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Output Parsers \n",
    "\n",
    "The lang chain has a Pydantic output parsers to Parse the text data into multiple formats.\n",
    "Interesting part here to note is , even though I don't write anything on the summary template , still it gives me the extra information I asked in format instructions. \n",
    "\n",
    "Hence output parsers are really powerful plugin to be used in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel , Field\n",
    "from typing import List\n",
    "\n",
    "class PersonIntel(BaseModel):\n",
    "    summary : str = Field(description= \" Summary of the peron \")\n",
    "    facts:List[str]= Field(description= \" interesting facts of the person\")\n",
    "    skills:List[str] = Field(description= \"Key Skills of the Person\")\n",
    "    work:str = Field(description=\"Company Name and Occupation\")\n",
    "    ice_breakers : List[str] = Field(description='Create Ice Breakers to open  a conversation with the person')\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {'summary':self.summary,\n",
    "                'facts': self.facts,\n",
    "                'skills': self.skills,\n",
    "                'work':self.work,\n",
    "                'ice_breakers':self.ice_breakers\n",
    "                }\n",
    "    \n",
    "person_intel_parser = PydanticOutputParser(pydantic_object=PersonIntel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model : gpt-3.5-turbo\n",
      "{\n",
      "    \"summary\": \"Eden Marco is a customer engineer at Google and a best-selling instructor on Udemy.\",\n",
      "    \"facts\": [\n",
      "        \"Eden has over 9k enrolled students and 800+ ratings with a solid 4.7 ★ rating on Udemy.\",\n",
      "        \"Before starting his career in tech, Eden served as a captain in the Israel Defense Forces.\"\n",
      "    ],\n",
      "    \"skills\": [\n",
      "        \"Backend development\",\n",
      "        \"Cloud computing\",\n",
      "        \"Teaching and course production\",\n",
      "        \"Functional programming\",\n",
      "        \"Computer science education\"\n",
      "    ],\n",
      "    \"work\": \"Google, Customer Engineer\",\n",
      "    \"ice_breakers\": [\n",
      "        \"What inspired you to start teaching software engineering?\",\n",
      "        \"What's the most surprising thing you've learned working at Google?\",\n",
      "        \"What was it like serving in the Israel Defense Forces?\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# prompt \n",
    "summary_template = \"\"\" given the information {information} about  a person from I want you to create:\n",
    "                        1. A short summary as summary:\n",
    "                        2. Two interesting facts about the person as Interesting Facts: \n",
    "                        3. company He is currently working as Company Name and Occupation : \n",
    "                        4. Highlight the key skills of person in bullet points as Key skills :  \n",
    "                        5. Create Ice Breakers to open  a conversation with the person .\n",
    "                        \\n{format_instructions}\n",
    "\n",
    "                    \"\"\"\n",
    "summary_prompt_template = PromptTemplate(\n",
    "            template=summary_template,\n",
    "            input_variables=[\"information\"],\n",
    "            partial_variables= {'format_instructions': person_intel_parser.get_format_instructions()}\n",
    "            )\n",
    "# input var is information we run the cahin keyword is information is valid.\n",
    "llm = ChatOpenAI(temperature=1,model_name=\"gpt-3.5-turbo\")\n",
    "print(\"LLM model :\",llm.model_name)\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=summary_prompt_template)\n",
    "result = chain.run(information=data_prime)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills :\n",
      "\tBackend development\n",
      "\tCloud computing\n",
      "\tTeaching and course production\n",
      "\tFunctional programming\n",
      "\tComputer science education\n",
      "Questions to User :\n",
      "\tWhat inspired you to start teaching software engineering?\n",
      "\tWhat's the most surprising thing you've learned working at Google?\n",
      "\tWhat was it like serving in the Israel Defense Forces?\n",
      "work: Google, Customer Engineer\n"
     ]
    }
   ],
   "source": [
    "print(\"Skills :\")\n",
    "[print(\"\\t{}\".format(s)) for s in  person_intel_parser.parse(result).skills]\n",
    "print(\"Questions to User :\")\n",
    "[print(\"\\t{}\".format(q)) for q in person_intel_parser.parse(result).ice_breakers]\n",
    "\n",
    "print(\"work:\", person_intel_parser.parse(result).work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
