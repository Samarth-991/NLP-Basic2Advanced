{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models available :64\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\" \n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(\"Total number of models available :{}\".format(len(openai.Model.list()['data'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-1 | babbage | gpt-3.5-turbo | davinci | text-davinci-edit-001 | text-davinci-003 | babbage-code-search-code | text-similarity-babbage-001 | code-davinci-edit-001 | text-davinci-001 | ada | babbage-code-search-text | babbage-similarity | code-search-babbage-text-001 | text-curie-001 | code-search-babbage-code-001 | text-ada-001 | text-embedding-ada-002 | text-similarity-ada-001 | curie-instruct-beta | ada-code-search-code | ada-similarity | code-search-ada-text-001 | text-search-ada-query-001 | davinci-search-document | ada-code-search-text | text-search-ada-doc-001 | davinci-instruct-beta | text-similarity-curie-001 | code-search-ada-code-001 | ada-search-query | text-search-davinci-query-001 | curie-search-query | davinci-search-query | babbage-search-document | ada-search-document | text-search-curie-query-001 | text-search-babbage-doc-001 | curie-search-document | text-search-curie-doc-001 | babbage-search-query | text-babbage-001 | text-search-davinci-doc-001 | text-search-babbage-query-001 | curie-similarity | curie | gpt-3.5-turbo-0301 | text-similarity-davinci-001 | text-davinci-002 | davinci-similarity | cushman:2020-05-03 | ada:2020-05-03 | babbage:2020-05-03 | curie:2020-05-03 | davinci:2020-05-03 | if-davinci-v2 | if-curie-v2 | if-davinci:3.0.0 | davinci-if:3.0.0 | davinci-instruct-beta:2.0.0 | text-ada:001 | text-davinci:001 | text-curie:001 | text-babbage:001 | "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for model_name in openai.Model.list()['data']:\n",
    "    models.append(model_name['id'])\n",
    "    print(model_name['id'],end=\" | \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Model ['whisper-1']\n",
      "text models ['text-davinci-edit-001', 'text-davinci-003', 'text-similarity-babbage-001', 'text-davinci-001', 'babbage-code-search-text', 'code-search-babbage-text-001', 'text-curie-001', 'text-ada-001', 'text-embedding-ada-002', 'text-similarity-ada-001', 'code-search-ada-text-001', 'text-search-ada-query-001', 'ada-code-search-text', 'text-search-ada-doc-001', 'text-similarity-curie-001', 'text-search-davinci-query-001', 'text-search-curie-query-001', 'text-search-babbage-doc-001', 'text-search-curie-doc-001', 'text-babbage-001', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'text-similarity-davinci-001', 'text-davinci-002', 'text-ada:001', 'text-davinci:001', 'text-curie:001', 'text-babbage:001']\n",
      "Chat models ['gpt-3.5-turbo', 'gpt-3.5-turbo-0301']\n"
     ]
    }
   ],
   "source": [
    "audio_model = [model_name for model_name in models if model_name.startswith('whisper')]\n",
    "text_model = [model_name for model_name in models if 'text' in model_name]\n",
    "chat_model = [model_name for model_name in models if model_name.startswith(\"gpt\")]\n",
    "print(\"Audio Model {}\".format(audio_model))\n",
    "print(\"text models {}\".format(text_model))\n",
    "print(\"Chat models {}\".format(chat_model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ChatGPT models \n",
    "* Model endpoint compatibility\n",
    "- ENDPOINT\tMODEL NAME\t\n",
    "- /v1/chat/completions\tgpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-0301\t\n",
    "- /v1/completions\ttext-davinci-003, text-davinci-002, text-curie-001, text-babbage-001, text-ada-001, davinci, curie, babbage, ada\t\n",
    "- /v1/edits text-davinci-edit-001\ttext-davinci-edit-001, code-davinci-edit-001\t\n",
    "- /v1/audio/transcriptions\twhisper-1\t\n",
    "- /v1/audio/translations\twhisper-1\t\n",
    "- /v1/fine-tunes\tdavinci, curie, babbage, ada\t\n",
    "- /v1/embeddings\ttext-embedding-ada-002, text-search-ada-doc-001\t\n",
    "- /v1/moderations\ttext-moderation-stable, text-moderation-latest\n",
    "\n",
    "### GPT-3.5-turbo \n",
    "\n",
    "* Keep an eye on the tokens , can not be more than 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{'role':\"user\",\"content\":\"Will AI is going to dominate the word\"}])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat GPT Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply_content(msg):\n",
    "    reply_list = []\n",
    "    for reply in completion['choices']:\n",
    "        reply_list.append(reply['message']['content'].strip())\n",
    "    return reply_list\n",
    "\n",
    "def get_total_tokens(msg):\n",
    "    return completion['usage']['total_tokens']\n",
    "\n",
    "\n",
    "def get_completion_tokens(msg):\n",
    "    return completion['usage']['completion_tokens']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replies ['As an AI language model, I cannot provide an opinion on whether AI will dominate the world. However, many experts predict that AI will play a significant role in shaping the future of society, business, and technology. While some fear the consequences of AI domination, others believe that it may bring benefits such as increased efficiency, productivity, and innovation. Ultimately, the development and deployment of AI technology will depend on how individuals and organizations choose to utilize it.']\n",
      "Comlpetion Tokens 90\n",
      "Tokens Used : 106\n"
     ]
    }
   ],
   "source": [
    "reply_content = get_reply_content(completion)\n",
    "print(\"Replies {}\".format(reply_content))\n",
    "print(\"Comlpetion Tokens {}\".format(get_completion_tokens(completion)))\n",
    "print(\"Tokens Used : {}\".format(get_total_tokens(completion)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History - Mangage own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_history = []\n",
    "user_input = input(\">:\")\n",
    "\n",
    "print(\"User input was: {}\".format(user_input))\n",
    "msg_history.append({\"role\":\"user\",\"content\":user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=msg_history)\n",
    "\n",
    "msg_history.append({\"role\":\"assistant\",\"content\": get_reply_content(completion)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Completion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txtcomp(rawtxt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello on Chat GPT\"},\n",
    "            {\"role\": \"user\", \"content\": rawtxt},\n",
    "        ]\n",
    "            )\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\">:\")\n",
    "print(txtcomp(user_input))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "#### Text-Davinci-003\n",
    "* Model  : Can do any language task with better quality, longer output, and consistent instruction-following than the curie, babbage, or ada models. Also supports inserting completions within text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summpred(rawtxt):\n",
    "    text_sum = \"Summarize this for 9th grade student:\\n\\n\"+rawtxt\n",
    "    completion = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=text_sum,\n",
    "    temperature=0.7,  ## Generate randomness in the output\n",
    "    max_tokens = 64,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "    )   \n",
    "\n",
    "    response = completion.choices[0].text\n",
    "    return response\n",
    "\n",
    "test_text = \"We are stuck to create a production ready pipeline because of overture delayed timelines for MSFT building footprints.So for now we are going to evaluate our model how it performs on POI signals and will keep venturing on other signals like GPS and street imagenary to improve APA score for USA and GBR countries\"\n",
    "print(summpred(test_text))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat GPT Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_media_path = \"/mnt/c/Users/medha/Downloads/Video/testing4_audio.mp4\"\n",
    "test_media = open(test_media_path,'rb')\n",
    "\n",
    "response = openai.Audio.transcribe(api_key='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',model='whisper-1',file=test_media,prompt='')\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT/OPenAI Andrew NG course"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propmting Guide lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_= load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Principles\n",
    "- Principle 1: Write clear and specific instructions\n",
    "- Principle 2: Give the model time to “think”\n",
    "##  Tactics\n",
    "### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "Delimiters can be anything like: ```, \"\"\", < >:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear and specific instructions should be provided to guide a model towards the desired output, and longer prompts can provide more clarity and context for the model, leading to more detailed and relevant outputs.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ask to provide a formated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"book_id\": 1,\n",
      "    \"title\": \"The Lost City of Zorath\",\n",
      "    \"author\": \"Aria Blackwood\",\n",
      "    \"genre\": \"Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 2,\n",
      "    \"title\": \"The Last Survivors\",\n",
      "    \"author\": \"Ethan Stone\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 3,\n",
      "    \"title\": \"The Secret Life of Bees\",\n",
      "    \"author\": \"Lila Rose\",\n",
      "    \"genre\": \"Romance\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASk to model to check if steps are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - Add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few shot promting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Resilience is like a tree that bends with the wind but never breaks. It is the ability to bounce back from adversity and keep moving forward, even when things get tough. Just like a tree that grows stronger with each storm it weathers, resilience is a quality that can be developed and strengthened over time.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal 2\n",
    "- give model time to think. \n",
    "- For complex problems - instruct model to take time "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 \n",
    "Specify multiple steps \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Two siblings, Jack and Jill, go on a quest to fetch water from a hilltop well, but misfortune strikes as they both fall down the hill, yet they return home slightly battered but with their adventurous spirits undimmed.\n",
      "\n",
      "Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits au sommet d'une colline, mais ils tombent tous les deux et retournent chez eux légèrement meurtris mais avec leur esprit d'aventure intact. \n",
      "Noms: Jack, Jill.\n",
      "\n",
      "{\n",
      "\"french_summary\": \"Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits au sommet d'une colline, mais ils tombent tous les deux et retournent chez eux légèrement meurtris mais avec leur esprit d'aventure intact.\",\n",
      "\"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Summary: Jack and Jill go on a quest to fetch water, but misfortune strikes and they tumble down the hill, returning home slightly battered but with their adventurous spirits undimmed. \n",
      "Translation: Jack et Jill partent en quête d'eau, mais la malchance frappe et ils dégringolent la colline, rentrant chez eux légèrement meurtris mais avec leurs esprits aventureux intacts.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"french_summary\": \"Jack et Jill partent en quête d'eau, mais la malchance frappe et ils dégringolent la colline, rentrant chez eux légèrement meurtris mais avec leurs esprits aventureux intacts.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in Italian summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = get_completion(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruct the model to work things out instead of rushing to conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the student's solution is actually not correct.\n",
    "#### We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "No\n",
      "\n",
      "Student grade:\n",
      "Incorrect\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Limitations: Hallucinations\n",
    "- Boie is a real company, the product name is not real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manda aunty was a kind and jolly woman who lived in a small village. She was known for her love for samosas, and she would often make them at home and share them with her neighbors. One day, Manda aunty was walking back home from the market with a bag full of samosas when she heard a rustling sound behind her.\n",
      "\n",
      "As she turned around, she saw a big, ferocious wolf staring at her with hungry eyes. Manda aunty was scared, but she didn't want to lose her precious samosas. So, she tried to run away, but the wolf was too fast for her. The wolf chased her and finally caught her by the arm.\n",
      "\n",
      "Manda aunty was trembling with fear, but she didn't give up. She knew that she had to save her samosas at any cost. So, she offered the wolf a samosa, hoping that it would satisfy his hunger. The wolf was surprised by her offer, but he couldn't resist the delicious smell of the samosas.\n",
      "\n",
      "Manda aunty gave him one samosa after another, and the wolf kept eating them greedily. As he ate, Manda aunty slowly moved away from him, and finally, she managed to escape. She ran back home, panting and sweating, but she was relieved that she had saved her samosas.\n",
      "\n",
      "From that day on, Manda aunty became more careful while walking alone in the woods. She never forgot the incident with the wolf, but she also never stopped making her delicious samosas. Her neighbors would often tease her about the incident, but they also admired her bravery and love for food.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me the story of manda aunty who likes eating Samosa and was caught by a wolf.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft and cute panda plush toy loved by daughter, but a bit small for the price. Arrived early.\n"
     ]
    }
   ],
   "source": [
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
